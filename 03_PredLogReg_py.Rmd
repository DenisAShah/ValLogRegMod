---
title: "Development and validation of logistic regression risk prediction models"
always_allow_html: true
output:
  github_document:
    toc: true
    toc_depth: 5
  keep_text: true
  pandoc_args: --webtex
---

## Steps
  
The steps taken in this file are:   
1. To develop a logistic regression risk prediction model.  
2. To assess the performance of the model in terms of calibration, discrimination and overall prediction error. We calculate the apparent, internal (optimism-corrected) validation and the external validation.  
3. To assess the potential clinical utility the model using decision curve analysis.  

### Installing and loading packages and import data

The following libraries are used in this file, the code chunk below will a) check whether you already have them installed, b) install them for you if not already present, and c) load the packages into the session.

```{r setup, include=FALSE}
# Knitr options
knitr::opts_chunk$set(
  fig.retina = 3,
  fig.path = "imgs/03_PredLogReg_py/",
  echo = FALSE
)
```

```{python, wdlib, message=FALSE, warning=FALSE, echo=TRUE}
# Load libraries and data
import warnings
warnings.simplefilter(action = "ignore", category = FutureWarning)
warnings.filterwarnings("ignore", category = RuntimeWarning) # suppressing warnings
import pandas as pd
import numpy as np
import scipy as sp
import tableone as tb
import statsmodels.api as smf
import matplotlib.pyplot as plt
import sklearn as sk
import seaborn as sns


# Get work directory
# os.getcwd()
url_rdata = "https://raw.githubusercontent.com/danielegiardiello/ValLogRegMod/main/Data/rdata.csv"
url_vdata = "https://raw.githubusercontent.com/danielegiardiello/ValLogRegMod/main/Data/vdata.csv"
# NOTE: go to 
# "https://github.com/danielegiardiello/ValLogRegMod/blob/main/Data/vdata.csv"
# then click" Raw" button to the upper right corner of the file preview.
# Copy and paste the url link to have the raw gitHub version of the data
rdata = pd.read_csv(url_rdata)
vdata = pd.read_csv(url_vdata)
# Inspect data:
# print(rdata.head(5)) # print the first five rows
# print(vdata.head(5)) # print the first five rows
# rdata.info() # inspect data as in R str()
# vdata.info() # inspect data as in R str()

## Data manipulation ----
# Development data 
# Converting categorical variables to dummies
rdata = pd.get_dummies(data = rdata, 
                       columns = ["ter_pos", "preafp", "prehcg"])
# Dropping columns not needed
rdata.drop(["ter_pos_No", "preafp_No", "prehcg_No"], 
           axis = 1, inplace = True)

# Validation data 
vdata = pd.get_dummies(data = vdata, 
                       columns=["ter_pos", "preafp", "prehcg"])
# Dropping columns not needed
vdata.drop(["ter_pos_No", "preafp_No", "prehcg_No"],
            axis = 1,
            inplace = True)
```

### Data description
Men with metastatic non-seminomatous testicular cancer can often be cured nowadays by cisplatin based chemotherapy. After chemotherapy, surgical resection is a generally accepted treatment to remove remnants of the initial metastases, since residual tumor may still be present. In the absence of tumor, resection has no therapeutic benefits, while it is associated with hospital admission, and risks of permanent morbidity and mortality. Logistic regression models were developed to predict the presence of residual tumor, combining  well-known predictors, such as the histology of the primary tumor, pre-chemotherapy levels of tumor markers, and (reduction in) residual mass size.  
We first consider a data set (rdata) with 544 patients to develop a prediction model that includes 5 predictors. We then extend this model with the pre-chemotherapy level of the tumor marker lactate dehydrogenase (LDH). This illustrates ways to assess the incremental
value of a marker. LDH values were log transformed, after standardizing by dividing by the local upper levels of normal values, after examination of non-linearity with restricted cubic spline functions.  

We  first consider a data set with 544 patients to develop a prediction model that includes 5 predictors (rdata).  In a later study, we externally validated the 5 predictor model in 273 patients from a tertiary referral center (vdata). We illustrate ways to assess the usefulness of a model in a new setting.  
We then extend the developed model with the pre-chemotherapy level of the tumor marker lactate dehydrogenase (LDH). Since the validation data (vdata) did not have information about LDH, we assess the prediction performances of the basic model in the development (rdata) and in the validation data (vdata). 
Thus, we loaded the development data (rdata) and the validation data (vdata).    
More details about development and validation data are provided in the manuscript ["Assessing the performance of prediction models: a framework for some traditional and novel measures"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3575184/) by Steyerberg et al. (2010).

#### Descriptive statistics

```{python, import, message=F, warning=F, comment=F}
# Get work directory
# os.getcwd()
url_rdata = "https://raw.githubusercontent.com/danielegiardiello/ValLogRegMod/main/Data/rdata.csv"
url_vdata = "https://raw.githubusercontent.com/danielegiardiello/ValLogRegMod/main/Data/vdata.csv"
# NOTE: go to 
# "https://github.com/danielegiardiello/ValLogRegMod/blob/main/Data/vdata.csv"
# then click" Raw" button to the upper right corner of the file preview.
# Copy and paste the url link to have the raw gitHub version of the data
rsel = pd.read_csv(url_rdata)
rsel = rsel.assign(dt = "Development data")

vsel = pd.read_csv(url_vdata)
vsel = vsel.assign(dt = "Validation data")

# Combine data
cdata = pd.concat([rsel, vsel], axis = 0)
cdata = cdata.reset_index()
columns = ["tum_res", "ter_pos", "preafp", "prehcg", "sqpost", "reduc10", "lnldhst"]
groupby = ["dt"]
categorical = ["tum_res","ter_pos","preafp", "prehcg"]
nonnormal = ["sqpost","reduc10","lnldhst"]
min_max = ["sqpost","reduc10","lnldhst"]

labels = {'tum_res': 'Residual tumor resection',
 'ter_pos': 'Primary tumor teratoma positive', 
 'preafp' : 'Elevated prechemotherapy AFP',
 'prehcg' : 'Elevated Prechemotherapy HCG',
 'sqpost' : 'Square root of mass size',
 'reduc10': 'Reduction in mass size per 10%' ,
 'lnldhst': 'log(LDH)'
}
        
Table1 = tb.TableOne(cdata, 
                  columns = columns, 
                  categorical = categorical, 
                  groupby = groupby, 
                  nonnormal = nonnormal, 
                  min_max = min_max,
                  rename = labels, 
                  missing = False,
                  pval = False,
                  remarks = False,
                  overall = False)

print(Table1.tabulate(tablefmt = "fancy_grid"))   
```


## Goal 1 - Develop a logistic regression risk prediction model

### 1.1 Check non-linearity of continuous predictors

Here we investigate the potential non-linear relation between continuous predictors and the outcomes. We apply three-knot restricted cubic splines  (details are given in e.g. Frank Harrell's book 'Regression Model Strategies (second edition)', page 27. We assess the potential non-linearity graphically (plotting the two continuous predictors against the log odds (XB or linear predictor) of both event types. Also, we compare the models with and without splines based on the AIC.

<details>
  <summary>Click to expand code</summary>
```{python, ff, warning=FALSE, fig.align='center', eval=FALSE, echo=TRUE}

# Formula restricted cubic spline
# k = #knots
# X1 = X
# X_j+1 = (X - t_j)_+**3 - (X - t_k-1)_+**3 * (t_k - t_j) / (t_k - t_k-1)
# + (X - t_k)_+**3 (t_k-1 - t_j)((t_k - t_k-1))
# Models without splines

# Models with splines
# Create function to calculate restricted cubic splines with three knots
def rcs_3(x):
    res_x = np.zeros((len(rdata), 1))
    qknots = [.1, .5, .9]
    knots = np.quantile(x, q = qknots)
    res_x[:, 0] = (np.power(np.clip((x - knots[0]), a_min = 0, a_max = None), 3) - np.power(np.clip((x - knots[1]), a_min = 0, a_max = None), 3) *((knots[2] - knots[0])/(knots[2] - knots[1])) + np.power(np.clip((x - knots[2]), a_min = 0, a_max = None), 3) * ((knots[1] - knots[0])/(knots[2] - knots[1]))) / ((knots[2] - knots[0])**2)
    return(res_x)
# NOTE: to be extended for 4,5, 6 and 7 knots

# Add splines to data frame
rdata["sq_rcs1"] = rcs_3(rdata.sqpost)
rdata["reduc10_rcs1"] = rcs_3(rdata.reduc10)

# Predictors data with splines
X =  rdata[["ter_pos_Yes", "preafp_Yes", "prehcg_Yes", 
            "sqpost", "sq_rcs1", "reduc10", "reduc10_rcs1"]]
X = X.assign(intercept = 1.0)

# Predictors without splines
X2 =  rdata[["ter_pos_Yes", "preafp_Yes", "prehcg_Yes", 
            "sqpost", "reduc10"]]
X2 = X2.assign(intercept = 1.0)
 
# Fitting Generalised linear model on transformed dataset
fit_rcs = smf.GLM(rdata.tum_res, X,  family = smf.families.Binomial()).fit()
fit = smf.GLM(rdata.tum_res, X2, family = smf.families.Binomial()).fit()

# Save predictors of the validation model
coeff_rcs = fit_rcs.params
cov_rcs = X         

# Calculating the linear predictor (X*beta)
lp_rcs = np.matmul(cov_rcs, coeff_rcs)

# Non-lineary of sqpost adjusted for the other predictors
cov_rcs = cov_rcs.assign(ter_pos_Yes = 0,
                         preafp_Yes = 0,
                         prehcg_Yes = 0,
                         reduc10 = np.median(rdata.reduc10),
                         reduc10_rcs1 = np.median(rdata.reduc10_rcs1))


# Calculating the lp of sqpost adjusted for the other predictors
lp_rcs_sq = np.matmul(cov_rcs, coeff_rcs)

# Calculating standard errors
vcov = fit_rcs.cov_params()

# Matrix X *%* vcov *%* t(X) (sqrt of the diagonal)
std_err = np.power(np.diagonal(cov_rcs.dot(vcov).dot(pd.DataFrame.transpose((cov_rcs)))), 1/2)

# Save to df
alpha = 0.05
df_rcs_sq = pd.DataFrame(
  {"sq" : rdata.sqpost,
   "lp_rcs_sq" : lp_rcs_sq,
   "std_err" : std_err,
   'lower_95' :  lp_rcs_sq - sp.stats.norm.ppf(1 - alpha / 2) * std_err,
   'upper_95' : lp_rcs_sq + sp.stats.norm.ppf(1 - alpha / 2) * std_err}
)

# Sorting by sqpost
df_rcs_sq = df_rcs_sq.sort_values(by = ['sq']) # sort
# df_rcs = pd.Series({c: df_rcs[c].unique() for c in df_rcs}) # unique values

# Non-lineary assessment of reduc10 adjusted for the other covariates
cov_rcs = cov_rcs.assign(ter_pos_Yes = 0,
                         preafp_Yes = 0,
                         prehcg_Yes = 0,
                         sqpost = np.median(rdata.sqpost),
                         sq_rcs1 = np.median(rdata.sq_rcs1),
                         reduc10 = rdata.reduc10,
                         reduc10_rcs1 = rdata.reduc10_rcs1)

lp_rcs_reduc10 = np.matmul(cov_rcs, coeff_rcs)

# Matrix X *%* vcov *%* t(X) (sqrt of the diagonal)
std_err = np.power(np.diagonal(cov_rcs.dot(vcov).dot(pd.DataFrame.transpose((cov_rcs)))), 1/2)

# Save to df
alpha = 0.05
df_rcs_rd = pd.DataFrame(
  {"reduc10" : rdata.reduc10,
   "lp_rcs_reduc10" : lp_rcs_reduc10,
   "std_err" : std_err,
   'lower_95' :  lp_rcs_reduc10 - sp.stats.norm.ppf(1 - alpha / 2) * std_err,
   'upper_95' : lp_rcs_reduc10 + sp.stats.norm.ppf(1 - alpha / 2) * std_err}
)

df_rcs_rd = df_rcs_rd.sort_values(by = ['reduc10']) # sort

# Plotting
fig, (ax1, ax2) = plt.subplots(1, 2)

# First plot - predictor: sq ---
ax1.plot(df_rcs_sq.sq, df_rcs_sq.lp_rcs_sq, "-", 
         color = "black")
ax1.plot(df_rcs_sq.sq, df_rcs_sq.lower_95, "--", 
         color = "black")
ax1.plot(df_rcs_sq.sq, df_rcs_sq.upper_95, "--", 
         color = "black")
plt.setp(ax1, xlabel = 'Square root of postchemotherapy mass size')
plt.setp(ax1, ylabel = 'log Odds')

# Second plot - predictor: reduc10 ---
ax2.plot(df_rcs_rd.reduc10, df_rcs_rd.lp_rcs_reduc10, "-", 
         color = "black")
ax2.plot(df_rcs_rd.reduc10, df_rcs_rd.lower_95, "--", 
         color = "black")
ax2.plot(df_rcs_rd.reduc10, df_rcs_rd.upper_95, "--", 
         color = "black")
plt.setp(ax2, xlabel = 'Reduction in mass size per 10%')
plt.show()
plt.clf()
plt.cla()
plt.close('all')
```
</details>

```{python, ff, warning=FALSE, fig.align='center', eval=TRUE}
```

```{python, res_aic, fig.align='center'}
df_aic = pd.DataFrame({
  "AIC without splines" : fit.aic,
  "AIC with splines" : fit_rcs.aic
},
  index = [0]
)

print(df_aic.to_markdown())
```

Both the graphical comparison and the AIC comparison suggested no relevant departure from linear relations between the continuous predictors (square root of post-chemotherapy mass size and reduction in mass size) and the risk of residual tumor at post-chemotherapy resection.  

### 1.2 Examine the fit of the models

+ Logistic regression risk prediction model without LDH

```{python, summary_lrm1, fig.align='center',warning=FALSE}
X =  rdata[["ter_pos_Yes", "preafp_Yes", "prehcg_Yes", 
            "sqpost", "reduc10"]]
X.insert(0, 'intercept', 1.0)

fit_lrm = smf.GLM(rdata.tum_res, X, 
                   family = smf.families.Binomial()).fit()
fit_lrm.summary()
```

+ Logistic regression risk prediction model with LDH
```{python, summary_lrm2, fig.align='center',warning=FALSE}
X =  rdata[["ter_pos_Yes", "preafp_Yes", "prehcg_Yes", 
            "sqpost", "reduc10", "lnldhst"]]
X.insert(0, 'intercept', 1.0)

fit_lrm_ldh = smf.GLM(rdata.tum_res, X, 
                   family = smf.families.Binomial()).fit()
fit_lrm_ldh.summary()
```

The coefficients of the models indicated that positive tumor teratoma, elevated prechemoterapy AFP levels, elevated prechemoterapy HCG levels, postchemotherapy mass size (mm) (expressed in square root) are associated with higher risk to residual tumor after resection. Reduction in mass size is associated with a reduced risk to have residual tumor after resection.

### 1.3 Plot of predictors vs estimated in the validation data

To get further insight into the effect of the covariates, we plot the covariate values observed in the validation set against the estimated absolute risk of having residual tumor after resection. This gives an idea of the size of the effects.

<details>
  <summary>Click to expand code</summary>
```{python, plot_risk, fig.align='center',warning=FALSE, message=FALSE, echo=TRUE, eval=FALSE}
# Models -------------
X =  rdata[["ter_pos_Yes", "preafp_Yes", "prehcg_Yes", "sqpost", "reduc10"]]
X = X.assign(intercept = 1.0)

fit_lrm = smf.GLM(rdata.tum_res, X, family = smf.families.Binomial()).fit()

# Predictors - validation data                
X_val =  vdata[["ter_pos_Yes", "preafp_Yes", "prehcg_Yes", "sqpost", "reduc10"]]
X_val = X_val.assign(intercept = 1.0)

# Predicted probabilities estimated by the model in the validation data
vdata = vdata.assign(pred = fit_lrm.predict(X_val))

fig, (ax1, ax2) = plt.subplots(nrows = 2, ncols = 3)
fig.tight_layout(pad = 2.5) 
# Or:
# subplots_adjust(left = None, bottom = None, right = None, top = None, 
#                 wspace = None, hspace=None) # to modify margins
#

# Positive teratoma tumor
sns.boxplot(x = "ter_pos_Yes", y = "pred", 
            data = vdata, palette = "Blues", ax = ax1[0]).set(
      xlabel = "Positive teratoma tumor",
      ylabel = "Estimated risk"
            )
            
## Elevated AFP levels           
sns.boxplot(x = "preafp_Yes",
            y = "pred",
            data = vdata, palette = "Blues", ax = ax1[1]).set(
              xlabel = "Elevated AFP levels",
              ylabel = "Estimated risk"
            )
            
# Elevated HCG
sns.boxplot(x = "prehcg_Yes",
            y = "pred",
            data = vdata, palette = "Blues", ax = ax1[2]).set(
              xlabel = "Elevated HCG levels",
              ylabel = "Estimated risk"
)
            
# Square root of postchemotherapy mass size
# Perform lowess
lowess = smf.nonparametric.lowess
fit_lowess = lowess(vdata.sqpost,
                    vdata.pred,
                    frac = 2/3,
                    it = 0) # same f and iter parameters as R
sns.scatterplot(x = "sqpost",
                y = "pred",
                data = vdata, ax = ax2[0])
ax2[0].set_xlim(0, 20)
ax2[0].set_ylim(0, 1.2)
ax2[0].set_xlabel("Square root of postchemotherapy mass size", fontsize = 8)
ax2[0].set_ylabel("Estimated risk")
ax2[0].plot(fit_lowess[:, 1], fit_lowess[:, 0], "-", color = "red")

           
# Reduction mass size
# Perform lowess
lowess = smf.nonparametric.lowess
fit_lowess = lowess(vdata.reduc10,
                    vdata.pred, 
                    frac = 2/3,
                    it = 0) # same f and iter parameters as R
sns.scatterplot(x = "reduc10",
                y = "pred",
                data = vdata, ax = ax2[1]).set(
                  xlabel = "Reduction mass size",
                  ylabel = "Estimated risk"
)
ax2[1].set_xlim(0, 10)
ax2[1].set_ylim(0, 1.2)
ax2[1].plot(fit_lowess[:, 1], fit_lowess[:, 0], "-", color = "red")
plt.show()
plt.clf()
plt.cla()
plt.close('all')
```
</details>

```{python, plot_risk, fig.align='center', warning=FALSE, message=FALSE, eval=TRUE}
```

## Goal 2 - Assessing performance of a logistic regression risk prediction model

Here we evaluate the performance of the prediction model in terms of discrimination, calibration and overall prediction error. 
We assess the prediction performance of the developed model not including LDH internally and in an external data.   


### 2.1 Discrimination

We here calculate:  

+ The c-statistic: it is a rank order statistic for predictions against true outcomes. The concordance (c) statistic is the most commonly used performance measure to indicate the discriminative ability of generalized linear regression models. For a binary outcome, c is identical to the area under the Receiver Operating Characteristic (ROC) curve, which plots the sensitivity (true positive rate) against 1 – (false positive rate) for consecutive cutoffs for the probability of an outcome. Accurate predictions discriminate between those with and those without the outcome.

+ Discrimination slope: it can be used as a simple measure for how well subjects with and without the outcome are separated. It is calculated as the absolute difference in average predictions for those with and without the outcome. Visualization is readily possible with a box plot or a histogram, which will show less overlap between those with and those without the outcome for a better discriminating model. 
 

More details are in ["Assessing the performance of prediction models: a framework for some traditional and novel measures"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3575184/) by Steyerberg et al. (2010);


<details>
  <summary>Click to expand code</summary>
```{python, discrimination, warning=FALSE, message=FALSE, echo=TRUE}

## Fitting the logistic regression model ------------------
# Logistic regression using statsmodels library
y = rdata["tum_res"]
X = rdata[["ter_pos_Yes", "preafp_Yes", "prehcg_Yes", "sqpost", "reduc10"]]
X = X.assign(intercept = 1.0)

lrm = smf.GLM(y, X, family = smf.families.Binomial())
result_lrm = lrm.fit()
result_lrm.summary()


# Save estimated predicted probabilites in the development data
pred = result_lrm.predict(X)

# Save coefficients of the developed model
coeff = result_lrm.params

# Save predictors of the validation model
cov = vdata         
cov = cov.assign(intercept = 1.0)
cov = cov[["ter_pos_Yes", "preafp_Yes","prehcg_Yes", "sqpost", "reduc10", "intercept"]]

# Calculating the linear predictor (X*beta)
lp = np.matmul(cov, coeff)

# Calculated the estimated predicted probabilities in the validation data
pred_val = np.exp(lp) / (1 + np.exp(lp))

# Or just use:
# result_lrm.predict(cov)


# Discrimination -------------------
# C-statistic
import lifelines 
from lifelines.utils import concordance_index

# Create dataframe val_out containing all info useful
# to assess prediction performance
# y_val = outcome of the validation data
# lp = linear predictor calculated in the validation data
# pred_val = estimated predicted probability in the validation data
val_out =  pd.DataFrame({'y_val': vdata["tum_res"], 
                         'lp_val' : lp,
                         'pred_val' : pred_val})                      
val_out = val_out.assign(intercept = 1.0) # Add intercept

# Creating bootstrap data of validation set to estimate bootstrap
# confidence intervals of performance measures as
# c-stat, discrimination slope and brier score
# NOTE: I need to understand how to set up a random seed to reproduce
# the same boostrapped data
B = 2000
bval_out = {}
for j in range(B): 
  bval_out[j] = sk.utils.resample(val_out, 
      replace = True, 
      n_samples = len(val_out))


# Estimating c-statistic
cstat = concordance_index(val_out.y_val, val_out.lp_val)


# Discrimination slope
val_out_group = val_out.groupby("y_val").mean()
dslope = abs(val_out_group.pred_val[1] - val_out_group.pred_val[0])

# Bootstrap percentile
cstat_boot = [0] * B
val_bgroup = {}
dslope_boot = [0] * B
for j in range(B):
  cstat_boot[j] = concordance_index(bval_out[j].y_val, bval_out[j].lp_val)
  val_bgroup[j] = bval_out[j].groupby("y_val").mean().pred_val
  dslope_boot[j] = abs(val_bgroup[j][1] - val_bgroup[j][0])

# Save results
res_discr = np.reshape(
  (cstat,
   np.percentile(cstat_boot, q = 2.5),
   np.percentile(cstat_boot, q = 97.5), 
   
  dslope,
   np.percentile(dslope_boot, q = 2.5),
   np.percentile(dslope_boot, q = 97.5)),
   
   (2, 3)
)

res_discr = pd.DataFrame(res_discr, 
                         columns = ["Estimate", "2.5 %", "97.5 %"],
                         index = ["C-statistic", "Discrimination slope"])
res_discr


```
</details>
